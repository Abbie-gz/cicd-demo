name: Project pipeline

on: [ push ]

jobs:
  project-pipeline:

    runs-on: ubuntu-latest
    strategy:
      max-parallel: 4
      matrix:
        python-version: [ 3.7 ]

    env:
      DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
      DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}

    steps:
      - uses: actions/checkout@v1

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v1
        with:
          python-version: ${{ matrix.python-version }}

      - uses: actions/cache@v2
        id: cache
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
            ${{ runner.os }}-pip-

      - name: Install pip
        run: |
          python -m pip install --upgrade pip

      - name: Install dependencies
        run: |
          pip install dbx
          pip install -r requirements.txt

      - name: Run tests
        run: |
          echo "Launching tests"
          pytest

      - name: Prepare profile
        run: |
          echo "[profile-name]" >> ~/.databrickscfg
          echo "host = $DATABRICKS_HOST" >> ~/.databrickscfg
          echo "token = $DATABRICKS_TOKEN" >> ~/.databrickscfg

      - name: Build artifact
        run: |
          python setup.py bdist_wheel

      - name: Perform deployment on test
        run: |
          dbx deploy --environment=test

      - name: Launch job on test
        run: |
          dbx launch --environment=test --job=sample --trace



